'*' Things are stuff that *must* be done by the next release.

DownloadChunk::interested should take into consideration chunks being
downloaded?

Randomize the chunks list so we don't start all downloads at the same
spot.

After 25 seconds, choke a peer if no requests have been received?

Add average, max and total to rates. Will this be controlled by
choke/unchoke?

Set IP TOS

Add a snub factor. The more you upload without getting back, the
higher it goes. Add a start buffer.

Make configure do the peer id thingie automagically

Add config for how often we unchoke unknown peers vs good uploaders

Consider splitting up download_state's peer connection management and
download state stuff.

Recursively update the up/down rates in throttle.

Make a seperate class for doing read and write to buffer in PC.

Each throttle can have it's own rules to decide the priority it gets.

Frobnicate the tracker reconnect timeout.

Since I'm using these nice sigc++ signals, seperate the download/state
class into specific functions like peer/choking management,
data/delegation and such.

libCurl requires attention every second or so for timeouts.

bencode stores position in the stream where they were found? Copy the
stream? Or is the current system the only flexible one we can use?
Consider making the stringstream input only to allow for lightning
fast str().c_str(). (Check if it's isstream that does this)

Sane timeouts on handshakes.

Switch to a proper type for file offset/length and chunk length.



DELEGATOR STUFF

Different priorities don't properly affect interested/not interested.

* Add a delay between peer choking you and the list getting thrown out.

* Add message about pieces being ignored, so i can test the code.

Proper canceling of pieces in sendHave, unless only one can download a piece.

TRACKER STUFF

* Make it NAT friendly, add selectable DNS


API REDESIGN:

Exceptions are pushed out with signals, support different groups with
multiple signals.

* Add setting for download root.

* Fix the incoming queue/downloading piece thing.


AFTER API REDESIGN:

Add the option to not throw non-critical exceptions. This lets the
client be ignorant of errors while creating stuff. (Make some kind of
C friendly layer ontop)

Consider ways of optimizing bitfield memory usage. A bitfield with all
set shouldn't change ever... And do a count on number of set bits?

Bitfield class needs to use unsigned char


COOL STUFF THAT NEEDS TO BE DONE

Add lambda style operators to algo, use a wrapper class to get right
type for overloaded operators. (that gets discarded when not used)


OPTIMIZING

Can we check the fd_set's in any more efficient way?... reverse the
current setup?

Using lists for the sockets we're waiting on does provide for many
cache misses. (i would assume). find out if you can't use something more
clever. Sort by fd number? iterate only to that number?

Cache iterators to different borders, and update them as we add/remove?

Use iterators in StorageChunk::get_position instead.


DUMPING TORRENT FILES

Since gcc's std::string is ref counted, it would be cheap to retain
the bencoded torrent. Hash and path's are the only two that take any
space at all, and both are used as originally stored.

Does it make sense to have *.bt_part or similar suffixes on partially
downloaded files? This would be uncompatible with other clients, but
make it configurable? This is fully client size, though need to
support a way to move files.
