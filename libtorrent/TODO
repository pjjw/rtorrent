DownloadChunk::interested should take into consideration chunks being
downloaded?

Randomize the chunks list so we don't start all downloads at the same
spot.

Make peer::connection::read* static?

Setting for pipelining requests.

Make request list keep choked requests, though it needs to be done in
some other way.

After 25 seconds, choke a peer if no requests have been received?

Add average, max and total to rates. Will this be controlled by
choke/unchoke?

Set IP TOS

Optimize Rate::rate(), use integer seconds. (or bitshifted)

Add a snub factor. The more you upload without getting back, the
higher it goes. Add a start buffer.

Make configure do the peer id thingie automagically

Add config for how often we unchoke unknown peers vs good uploaders

Consider splitting up download_state's peer connection management and
download state stuff.

Recursively update the up/down rates in throttle.

Make a seperate class for doing read and write to buffer in PC.

Each throttle can have it's own rules to decide the priority it gets.

Frobnicate the tracker reconnect timeout.

Add host lookup+connection to SocketBase

Delegator doesn't need to copy the bitfield, do the notIn algorithm as
you iterate.

HttpGet should handle urls with only domain name (+port), without the
leading '/'.

Add compact and numwant.

Fair sharing of bandwidth to peers, sort them in some way? Or does the
kernel allow each to fill up their buffers, thereby making the order
in the SocketBase list irrelevant=

Since I'm using these nice sigc++ signals, seperate the download/state
class into specific functions like peer/choking management,
data/delegation and such.

Files class does stuff it isn't supposed to do, like keeping track of
how much is done and stuff.

libCurl requires attention every second or so for timeouts.

tracker "key" is 8 char hex, implement.

bencode stores position in the stream where they were found? Copy the
stream? Or is the current system the only flexible one we can use?
Consider making the stringstream input only to allow for lightning
fast str().c_str(). (Check if it's isstream that does this)

QS in client needs to be swapped.

Add stop/remove to client. (I'm too lazy... it should be really eays;)

Don't open with largefile unless the torrent requires it.

Can we make FileChunk either ref counted or move owner on copy?

Sane timeouts on handshakes.

Do something about tracker connect fails, they are not handled optimally.


API REDESIGN:

Let the client retrive the file names in the torrent. (Add support for
all in one string, or path broken up)

Exceptions are pushed out with signals, support different groups with
multiple signals.


AFTER API REDESIGN:

Add the option to not throw non-critical exceptions. This lets the
client be ignorant of errors while creating stuff. (Make some kind of
C friendly layer ontop)

Consider ways of optimizing bitfield memory usage. A bitfield with all
set shouldn't change ever...


COOL STUFF THAT NEEDS TO BE DONE

Add lambda style operators to algo, use a wrapper class to get right
type for overloaded operators. (that gets discarded when not used)


OPTIMIZING

Can we check the fd_set's in any more efficient way?... reverse the
current setup?

Using lists for the sockets we're waiting on does provide for many
cache hits. (i would assume). find out if you can't use something more
clever. Sort by fd number? iterate only to that number?

Cache iterators to different borders, and update them as we add/remove?

Use iterators in StorageChunk::get_position instead.


DUMPING TORRENT FILES

Since gcc's std::string is ref counted, it would be cheap to retain
the bencoded torrent. Hash and path's are the only two that take any
space at all, and both are used as originally stored.
