DownloadChunk::interested should take into consideration chunks being
downloaded?

Randomize the chunks list so we don't start all downloads at the same
spot.

Make peer::connection::read* static?

Setting for pipelining requests.

Make request list keep choked requests, though it needs to be done in
some other way.

After 25 seconds, choke a peer if no requests have been received?

Add average, max and total to rates. Will this be controlled by
choke/unchoke?

Set IP TOS

Optimize Rate::rate(), use integer seconds. (or bitshifted)

Add a snub factor. The more you upload without getting back, the
higher it goes. Add a start buffer.

Make configure do the peer id thingie automagically

Add config for how often we unchoke unknown peers vs good uploaders

Consider splitting up download_state's peer connection management and
download state stuff.

Recursively update the up/down rates in throttle.

Make a seperate class for doing read and write to buffer in PC.

Each throttle can have it's own rules to decide the priority it gets.

Frobnicate the tracker reconnect timeout.

Add host lookup+connection to SocketBase

Delegator doesn't need to copy the bitfield, do the notIn algorithm as
you iterate.

HttpGet should handle urls with only domain name (+port), without the
leading '/'.

Add compact and numwant.

Fair sharing of bandwidth to peers, sort them in some way? Or does the
kernel allow each to fill up their buffers, thereby making the order
in the SocketBase list irrelevant=

Since I'm using these nice sigc++ signals, seperate the download/state
class into specific functions like peer/choking management,
data/delegation and such.

Files class does stuff it isn't supposed to do, like keeping track of
how much is done and stuff.

libCurl requires attention every second or so for timeouts.

tracker "key" is 8 char hex, implement.

bencode stores position in the stream where they were found? Copy the
stream? Or is the current system the only flexible one we can use?
Consider making the stringstream input only to allow for lightning
fast str().c_str(). (Check if it's isstream that does this)


API REDESIGN:

Let the client retrive the file names in the torrent. (Add support for
all in one string, or path broken up)

Exceptions are pushed out with signals, support different groups with
multiple signals.


AFTER API REDESIGN:

Add the option to not throw non-critical exceptions. This lets the
client be ignorant of errors while creating stuff. (Make some kind of
C friendly layer ontop)
